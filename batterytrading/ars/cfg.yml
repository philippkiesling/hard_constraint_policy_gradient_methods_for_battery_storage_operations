# Config file for PPO


model:
  #("env", "Pendulum-v1"),
  env: BatteryStorageEnv
  learning_rate: schedule
  #policy: 'MlpLstmPolicy'
  #policy: 'MlpPolicy'
  policy: 'LinearPolicy'
  tensorboard_log: .log/log_tb/
  verbose: 1
  n_delta: 30
  n_top: 3
  delta_std: 0.35
  zero_policy: True
  alive_bonus_offset: 0
  n_eval_episodes: 100
  _init_setup_model: True
  policy_kwargs:
    activation_fn: tanh
    lstm_kwargs:
      enable_critic_lstm: False
      lstm_hidden_size: 128

train:
  total_timesteps: 100000
  eval_freq: 100
  log_interval: 1
  callback: null
  tb_log_name: "ARS"
  eval_env: null
  n_eval_episodes: 100
  eval_log_path: null
  reset_num_timesteps: True
  async_eval: null
  progress_bar: True

env:
  max_charge: 0.15
  total_storage_capacity: 1
  initial_charge: 0.0
  max_SOC: 1
  price_time_horizon: 1.5
  data_root_path: ""
  time_interval: "15min"
  n_past_timesteps: 4 # 24/4 timesteps corresponds to 6 hours of historic data as input
  time_features: True
  preprocessing:
    clipaction: True
    normalizeobservation: True
    normalizereward: True
    transformobservation: True
    transformreward: True

wandb:
  use_wandb: True
  project: "batterytrading"
  #entity: "batterytrading"
  name: "ARS_linear"
  resume: "allow"
  sync_tensorboard: True
  model_save_path: .log/wandb/modelNormalizeObservationPartiallys
